{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN 부분 한번 코드 수정해보았습니다. 한번 확인 부탁드려요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일 읽기\n",
    "df = pd.read_csv(\"./레이블부여된공지사항(수정본).csv\") \n",
    "\n",
    "notice_names = df['title'].tolist()\n",
    "\n",
    "# 전처리 함수 정의\n",
    "def preprocess_text(text):\n",
    "    # 특수문자 제거\n",
    "    text = re.sub(r\"[^\\uAC00-\\uD7A30-9a-zA-Z\\s]\", \"\", text)\n",
    "\n",
    "    # 숫자 정보 제거\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    # 형태소 분석\n",
    "    tagger = Okt()\n",
    "    words = tagger.morphs(text)\n",
    "\n",
    "    # 불용어 제거\n",
    "    stop_words = ['필독', '학기', '학년', '도', '년', '제', '회', '월', '학부', '일', '차', '년도', '안내']  # 불용어 리스트\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # 분석된 형태소들을 공백으로 결합하여 문장으로 반환\n",
    "    text = ' '.join(words)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "preprocessed_notice_names = [preprocess_text(notice_name) for notice_name in notice_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 긴 문장의 길이: 29\n",
      "어휘 사전의 크기: 6093\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 토크나이저 생성\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# 토크나이저가 데이터를 학습\n",
    "tokenizer.fit_on_texts(preprocessed_notice_names)\n",
    "\n",
    "# 데이터를 시퀀스로 변환\n",
    "sequences = tokenizer.texts_to_sequences(preprocessed_notice_names)\n",
    "\n",
    "# 가장 긴 문장의 길이를 확인\n",
    "max_sequence_length = max(len(s) for s in sequences)\n",
    "print('가장 긴 문장의 길이:', max_sequence_length)\n",
    "\n",
    "# 어휘 사전의 크기를 확인 (+1을 하는 이유는 0인덱스를 고려하기 때문입니다.)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('어휘 사전의 크기:', vocab_size)\n",
    "\n",
    "# 모든 문장을 가장 긴 문장의 길이로 패딩 처리\n",
    "padded_X = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF 벡터화\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(preprocessed_notice_names)\n",
    "\n",
    "tfidf_model = TfidfVectorizer().fit(preprocessed_notice_names)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터 분리: train 데이터 80%, test 데이터 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 변수 다중 클래스 원-핫 인코딩\n",
    "y_train_encoded = to_categorical(y_train)\n",
    "y_test_encoded = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 모델 생성\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 128, input_length=max_sequence_length))\n",
    "model.add(Conv1D(64, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# 출력 뉴런의 개수와 활성화 함수를 클래스 개수에 따라 조정\n",
    "num_classes = len(set(y))  # 클래스 개수 계산\n",
    "if num_classes == 2:\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "else:\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "248/248 [==============================] - 3s 10ms/step - loss: 5.7950 - accuracy: 0.0709 - val_loss: 5.2145 - val_accuracy: 0.1024\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 2s 8ms/step - loss: 3.8928 - accuracy: 0.2959 - val_loss: 2.8605 - val_accuracy: 0.4834\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 2s 8ms/step - loss: 1.6354 - accuracy: 0.6766 - val_loss: 1.5647 - val_accuracy: 0.7119\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 2s 8ms/step - loss: 0.6417 - accuracy: 0.8736 - val_loss: 1.1757 - val_accuracy: 0.7780\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 2s 8ms/step - loss: 0.2692 - accuracy: 0.9532 - val_loss: 1.0811 - val_accuracy: 0.8052\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 2s 8ms/step - loss: 0.1169 - accuracy: 0.9823 - val_loss: 1.0133 - val_accuracy: 0.8209\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 2s 8ms/step - loss: 0.0533 - accuracy: 0.9947 - val_loss: 1.0146 - val_accuracy: 0.8249\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 2s 8ms/step - loss: 0.0308 - accuracy: 0.9971 - val_loss: 1.0212 - val_accuracy: 0.8269\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 2s 8ms/step - loss: 0.0171 - accuracy: 0.9991 - val_loss: 1.0439 - val_accuracy: 0.8315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1da45e02ef0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "model.fit(X_train, y_train_encoded, epochs=10, batch_size=32, validation_data=(X_test, y_test_encoded), callbacks=[EarlyStopping(patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8314833501513622\n"
     ]
    }
   ],
   "source": [
    "y_prob = model.predict(X_test, verbose=0) \n",
    "y_pred = y_prob.argmax(axis=-1)\n",
    "accuracy = np.sum(y_pred.flatten() == y_test) / len(y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "입력 문장: [전공] 2023학년도 1학기 전공신청 및 변경안내\n",
      "예측된 레이블: 282\n"
     ]
    }
   ],
   "source": [
    "# 새로운 입력 데이터 예측\n",
    "new_text = input(\"새로운 문장을 입력하세요: \")\n",
    "preprocessed_new_text = preprocess_text(new_text)\n",
    "sequence = tokenizer.texts_to_sequences([preprocessed_new_text])\n",
    "padded_sequence = pad_sequences(sequence, maxlen=max_sequence_length, padding='post')\n",
    "prediction = model.predict(padded_sequence)\n",
    "predicted_label = label_encoder.inverse_transform([prediction.argmax()])[0]\n",
    "\n",
    "# 예측 결과 출력\n",
    "print(f\"입력 문장: {new_text}\")\n",
    "print(f\"예측된 레이블: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
